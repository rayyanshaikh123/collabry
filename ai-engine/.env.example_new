# ============================================================
# PRODUCTION-GRADE BACKEND CONFIGURATION
# Study Assistant Platform - Environment Variables
# ============================================================

# ========== Server Configuration ==========
HOST=0.0.0.0
PORT=8000
DEBUG=false
RELOAD=false

# ========== LLM Configuration (OpenAI-compatible) ==========
# Switch providers by changing these 3 lines ONLY

# Option 1: OpenAI (Production)
# OPENAI_API_KEY=sk-proj-...
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini

# Option 2: LM Studio (Local Development)
# OPENAI_API_KEY=lm-studio
# OPENAI_BASE_URL=http://localhost:1234/v1
# OPENAI_MODEL=llama-3.1-8b-instruct

# Option 3: Ollama (Local Development)
OPENAI_API_KEY=ollama
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_MODEL=llama3.1

# Option 4: OpenRouter (Cloud, Free Tier)
# OPENAI_API_KEY=sk-or-v1-...
# OPENAI_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_MODEL=meta-llama/llama-3.1-8b-instruct:free

# Option 5: Together AI
# OPENAI_API_KEY=...
# OPENAI_BASE_URL=https://api.together.xyz/v1
# OPENAI_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo

# LLM Parameters
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4096
OPENAI_STREAMING=true

# ========== Embeddings Configuration ==========
# Switch embedding providers

# Option 1: OpenAI Embeddings (Production)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSION=1536

# Option 2: Local Sentence-Transformers (Free)
EMBEDDING_PROVIDER=sentence-transformers
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Option 3: HuggingFace API (Cloud)
# EMBEDDING_PROVIDER=huggingface
# EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
# EMBEDDING_DIMENSION=384
# HF_API_KEY=hf_...

# ========== Vector Store Configuration ==========
# Switch vector databases

# Option 1: FAISS (Local, Simple, Default)
VECTOR_STORE=faiss
FAISS_INDEX_PATH=./data/faiss_index

# Option 2: Chroma (Local, Open Source)
# VECTOR_STORE=chroma
# CHROMA_PERSIST_DIR=./data/chroma_db
# CHROMA_COLLECTION=documents

# Option 3: Pinecone (Cloud, Production)
# VECTOR_STORE=pinecone
# PINECONE_API_KEY=...
# PINECONE_INDEX=study-assistant
# PINECONE_ENVIRONMENT=us-west-2

# Option 4: Qdrant (Local/Cloud, Open Source)
# VECTOR_STORE=qdrant
# QDRANT_URL=http://localhost:6333
# QDRANT_COLLECTION=documents
# QDRANT_API_KEY=  # Optional, for cloud

# ========== Database Configuration ==========
# MongoDB for conversation history
MONGODB_URI=mongodb://localhost:27017
MONGODB_DB=study_assistant

# MongoDB Atlas (Cloud)
# MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net
# MONGODB_DB=study_assistant

# ========== Authentication ==========
JWT_SECRET_KEY=dev-secret-change-in-production-use-openssl-rand-hex-32
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=1440

# ========== Agent Configuration ==========
MAX_AGENT_ITERATIONS=5
CONVERSATION_HISTORY_LIMIT=10

# ========== RAG Configuration ==========
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVAL_TOP_K=4

# ========== CORS Configuration ==========
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
CORS_ALLOW_CREDENTIALS=true

# ========== Rate Limiting ==========
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# ============================================================
# QUICK START CONFIGURATIONS
# ============================================================

# Free Local Development (No API Keys)
# ------------------------------------------------------------
# LLM: Ollama
# Embeddings: Sentence-Transformers
# Vector Store: FAISS
# Database: MongoDB (local)
#
# Steps:
# 1. Install Ollama: https://ollama.ai
# 2. Run: ollama pull llama3.1
# 3. Use the Ollama configuration above
# 4. Install: pip install sentence-transformers
# 5. Start MongoDB locally

# Production OpenAI
# ------------------------------------------------------------
# LLM: OpenAI GPT-4o-mini
# Embeddings: OpenAI text-embedding-3-small
# Vector Store: Pinecone
# Database: MongoDB Atlas
#
# Steps:
# 1. Get OpenAI API key: https://platform.openai.com
# 2. Get Pinecone API key: https://www.pinecone.io
# 3. Create MongoDB Atlas cluster: https://www.mongodb.com/cloud/atlas
# 4. Use the OpenAI + Pinecone + Atlas configuration above

# Hybrid (OpenRouter + Local)
# ------------------------------------------------------------
# LLM: OpenRouter (free tier)
# Embeddings: Sentence-Transformers (local)
# Vector Store: FAISS (local)
# Database: MongoDB Atlas (free tier)
#
# Steps:
# 1. Get OpenRouter API key: https://openrouter.ai
# 2. Create MongoDB Atlas free cluster
# 3. Use OpenRouter + sentence-transformers + FAISS config
