# Collabry AI Engine - Environment Configuration
# Copy this file to .env and fill in your values
# NEVER commit .env to version control!

# ==============================================================================
# SERVER CONFIGURATION
# ==============================================================================
# Server host (default: 0.0.0.0)
HOST=0.0.0.0

# Server port (default: 8000)
PORT=8000

# Debug mode - enables detailed logging (default: false)
DEBUG=false

# Auto-reload on code changes (default: false, enable for development)
RELOAD=false

# ==============================================================================
# LLM PROVIDER CONFIGURATION
# ==============================================================================
# Provider selection: openai, groq, ollama, or together
# Switch providers to avoid rate limits or for local testing
LLM_PROVIDER=openai

# ==============================================================================
# OPENAI CONFIGURATION (Production)
# ==============================================================================
# OpenAI API Key - Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# ==============================================================================
# GROQ CONFIGURATION (Alternative - Free Tier, Fast Inference)
# ==============================================================================
# Groq API Key - Free tier available at: https://console.groq.com
# Models: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
GROQ_API_KEY=
GROQ_BASE_URL=https://api.groq.com/openai/v1
GROQ_MODEL=llama-3.3-70b-versatile

# ==============================================================================
# OLLAMA CONFIGURATION (Alternative - Local, Free, No API Key)
# ==============================================================================
# Install: https://ollama.ai
# Run: ollama serve (starts on http://localhost:11434)
# Pull models: ollama pull llama3.2, ollama pull mistral
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.2

# ==============================================================================
# TOGETHER AI CONFIGURATION (Alternative - Generous Free Tier)
# ==============================================================================
# Together AI API Key - Free tier at: https://api.together.xyz
# Models: meta-llama/Llama-3.3-70B-Instruct-Turbo, mistralai/Mixtral-8x7B-Instruct-v0.1
TOGETHER_API_KEY=
TOGETHER_BASE_URL=https://api.together.xyz/v1
TOGETHER_MODEL=meta-llama/Llama-3.3-70B-Instruct-Turbo

# ==============================================================================
# SHARED LLM PARAMETERS (Applied to all providers)
# ==============================================================================
# LLM temperature for response randomness (0.0-1.0, default: 0.7)
LLM_TEMPERATURE=0.7

# Maximum tokens per response (default: 4096)
LLM_MAX_TOKENS=4096

# Enable streaming responses (default: true)
LLM_STREAMING=true

# Delay between API requests in seconds to avoid rate limits (default: 1.0)
# OpenAI: 1.5, Groq: 0.5, Ollama: 0.1, Together: 0.5
LLM_REQUEST_DELAY=1.0

# ==============================================================================
# FINE-TUNED MODEL CONFIGURATION (OPTIONAL)
# ==============================================================================
# Fine-tuned model ID (set after fine-tuning, e.g., ft:gpt-4o-mini:collabry:abc123)
# Leave empty to use base model
OPENAI_FINETUNED_MODEL=

# Use fine-tuned model if available (default: false)
# Set to true after fine-tuning to enable the custom model
USE_FINETUNED_MODEL=false

# ==============================================================================
# EMBEDDINGS CONFIGURATION
# ==============================================================================
# Embedding provider: openai or huggingface (default: openai)
EMBEDDING_PROVIDER=openai

# OpenAI embedding model (default: text-embedding-3-small)
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimension (default: 1536 for text-embedding-3-small)
EMBEDDING_DIMENSION=1536

# HuggingFace API key (only if using HuggingFace embeddings)
HF_API_KEY=

# ==============================================================================
# VECTOR STORE CONFIGURATION
# ==============================================================================
# Vector store type: faiss, chroma, pinecone, or qdrant (default: faiss)
VECTOR_STORE=faiss

# FAISS index storage path (default: ./data/faiss_index)
FAISS_INDEX_PATH=./data/faiss_index

# Chroma persist directory (if using Chroma)
# CHROMA_PERSIST_DIR=./data/chroma

# Pinecone configuration (if using Pinecone)
# PINECONE_API_KEY=
# PINECONE_ENVIRONMENT=
# PINECONE_INDEX_NAME=

# ==============================================================================
# MONGODB CONFIGURATION (REQUIRED)
# ==============================================================================
# MongoDB connection URI
# Local: mongodb://localhost:27017
# Cloud (MongoDB Atlas): mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&w=majority
MONGO_URI=mongodb://localhost:27017

# MongoDB database name (default: collabry)
MONGO_DB=collabry

# MongoDB collection for conversations (default: conversations)
MEMORY_COLLECTION=conversations

# ==============================================================================
# RAG CONFIGURATION
# ==============================================================================
# Number of documents to retrieve from vector store (default: 3)
RAG_TOP_K=3

# Minimum similarity score for relevance filtering (default: 0.7)
RAG_SIMILARITY_THRESHOLD=0.7

# Chunk size for document splitting (default: 500)
RAG_CHUNK_SIZE=500

# Chunk overlap for context continuity (default: 50)
RAG_CHUNK_OVERLAP=50

# ==============================================================================
# EXTERNAL API KEYS (ENABLES WEB SEARCH FOR COURSES)
# ==============================================================================
# Web search is REQUIRED for real-time course recommendations
# The AI will automatically use search_web tool when users ask about courses

# Serper API key (Recommended - Google Search API)
# Get FREE key at: https://serper.dev (100 free searches/month)
SERPER_API_KEY=

# Tavily API key (Alternative - AI-optimized search)
# Get FREE key at: https://tavily.com (1000+ free searches/month)
TAVILY_API_KEY=

# Without these keys, the AI will provide platform URLs but not live course data


# ==============================================================================
# LIVEKIT CONFIGURATION (Voice Tutor Feature)
# ==============================================================================
# LiveKit API Key (get from LiveKit Cloud dashboard)
# Get started at: https://livekit.io
LIVEKIT_API_KEY=

# LiveKit API Secret
LIVEKIT_API_SECRET=

# LiveKit WebSocket URL (format: wss://your-project.livekit.cloud)
# For self-hosted: ws://localhost:7880
LIVEKIT_WS_URL=

# ==============================================================================
# SECURITY (PRODUCTION ONLY)
# ==============================================================================
# JWT secret key for token validation (CHANGE IN PRODUCTION!)
# Must match the backend JWT_ACCESS_SECRET for authentication to work
JWT_SECRET_KEY=your-super-secret-access-token-key-change-this-in-production

# JWT algorithm (default: HS256)
JWT_ALGORITHM=HS256

# JWT token expiration in seconds (default: 86400 = 24 hours)
JWT_EXPIRATION=86400

# ==============================================================================
# LOGGING & MONITORING (OPTIONAL)
# ==============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
LOG_LEVEL=INFO

# Sentry DSN for error tracking (optional)
# SENTRY_DSN=

# ==============================================================================
# NOTES FOR DIFFERENT PROVIDERS
# ==============================================================================
# 
# OpenAI (Production):
#   OPENAI_BASE_URL=https://api.openai.com/v1
#   OPENAI_MODEL=gpt-4o-mini
#
# Azure OpenAI:
#   OPENAI_BASE_URL=https://your-resource.openai.azure.com/
#   OPENAI_API_KEY=your-azure-key
#   OPENAI_MODEL=your-deployment-name
#
# Local LM Studio:
#   OPENAI_BASE_URL=http://localhost:1234/v1
#   OPENAI_API_KEY=not-needed
#   OPENAI_MODEL=local-model-name
#
# Ollama (with OpenAI compatibility):
#   OPENAI_BASE_URL=http://localhost:11434/v1
#   OPENAI_API_KEY=not-needed
#   OPENAI_MODEL=llama3.2
#
# Together AI:
#   OPENAI_BASE_URL=https://api.together.xyz/v1
#   OPENAI_API_KEY=your-together-key
#   OPENAI_MODEL=meta-llama/Llama-3-8b-chat-hf